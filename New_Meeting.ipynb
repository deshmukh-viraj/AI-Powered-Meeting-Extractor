{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_0RMULb5cxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f61ad8f8-24c9-425d-c494-8e467a7c0ec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.14)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.1)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install librosa\n",
        "!pip install pydub\n",
        "!pip install huggingface-hub\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y ffmpeg"
      ],
      "metadata": {
        "id": "YLZM3gg35pQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e7f7f04-7170-4dc2-d8a2-a583bce559b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (91.189.91.82)] [Connected to cloud.r-pro\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,804 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,404 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [56.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,566 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,917 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [51.0 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [48.5 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,262 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,080 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,763 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,092 kB]\n",
            "Get:22 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,752 kB]\n",
            "Fetched 33.2 MB in 4s (9,051 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import torch\n",
        "import librosa\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import gradio as gr\n",
        "from typing import Dict, List\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Configuration\n",
        "WHISPER_MODEL = \"base\"\n",
        "LLM_MODEL = \"microsoft/DialoGPT-medium\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "pYeOdRyb6VRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a55c2f-9123-4c82-a691-5d6c09d42fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioProcessor:\n",
        "    def __init__(self, model_size=WHISPER_MODEL):\n",
        "        print(f\"Loading Whisper Model: {model_size}\")\n",
        "        self.model = whisper.load_model(model_size)\n",
        "        print(\"Whisper Model Loaded Successfully\")\n",
        "\n",
        "    def transcribe_audio(self, audio_path):\n",
        "        \"\"\"Transcribe audio file to text\"\"\"\n",
        "        try:\n",
        "            print(\"Starting transcription.....\")\n",
        "            result = self.model.transcribe(audio_path)\n",
        "            print(\"Transcription Completed\")\n",
        "            return {\n",
        "                \"text\": result[\"text\"],\n",
        "                \"segments\": result.get(\"segments\", []),\n",
        "                \"language\": result.get(\"language\", \"en\")\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error During Transcription: {str(e)}\")\n",
        "            return {\"text\": \"\", \"segments\": [], \"language\": \"en\"}"
      ],
      "metadata": {
        "id": "QkBcm88Q6YVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MeetingAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.action_words = ['todo', 'action', 'task', 'assign', 'result', 'responsible', 'deadline', 'due', 'complete', 'finish']\n",
        "        self.decision_words = ['decide', 'agreed', 'concluded', 'resolved', 'determined', 'final', 'approved']\n",
        "        self.common_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'will', 'would', 'could', 'should', 'have', 'has', 'had', 'do', 'does', 'did', 'can', 'may', 'might', 'must', 'shall', 'should', 'will', 'would'}\n",
        "\n",
        "    def extract_sentences_with_keywords(self, text, keywords):\n",
        "        \"\"\"Extract sentences containing specific keywords\"\"\"\n",
        "        sentences = re.split(r'[.!?]+', text)\n",
        "        relevant_sentences = []\n",
        "        for sentence in sentences:\n",
        "            sentence = sentence.strip()\n",
        "            if sentence and any(keyword in sentence.lower() for keyword in keywords):\n",
        "                relevant_sentences.append(sentence)\n",
        "        return relevant_sentences\n",
        "\n",
        "    def analyze_meeting(self, transcript, meeting_title=\"Team Meeting\"):\n",
        "        \"\"\"Analyze meeting transcript and extract key information\"\"\"\n",
        "        try:\n",
        "            # Handle both dict and string inputs\n",
        "            if isinstance(transcript, dict):\n",
        "                text = transcript.get('text', '')\n",
        "            else:\n",
        "                text = str(transcript)\n",
        "\n",
        "            if not text:\n",
        "                return {\n",
        "                    \"summary\": \"No transcript available for analysis\",\n",
        "                    \"action_items\": [],\n",
        "                    \"decisions\": [],\n",
        "                    \"participants\": [],\n",
        "                    \"key_topics\": []\n",
        "                }\n",
        "\n",
        "            # Extract information\n",
        "            action_sentences = self.extract_sentences_with_keywords(text, self.action_words)\n",
        "            decision_sentences = self.extract_sentences_with_keywords(text, self.decision_words)\n",
        "            participants = self.extract_participants(text)\n",
        "            summary = self.generate_summary(text, meeting_title)\n",
        "            topics = self.extract_topics(text)\n",
        "\n",
        "            return {\n",
        "                \"summary\": summary,\n",
        "                \"action_items\": action_sentences[:5],\n",
        "                \"decisions\": decision_sentences[:5],\n",
        "                \"participants\": participants,\n",
        "                \"key_topics\": topics\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error During Analysis: {str(e)}\")\n",
        "            return {\n",
        "                \"summary\": \"Error analyzing meeting\",\n",
        "                \"action_items\": [],\n",
        "                \"decisions\": [],\n",
        "                \"participants\": [],\n",
        "                \"key_topics\": []\n",
        "            }\n",
        "\n",
        "    def extract_participants(self, text):\n",
        "        \"\"\"Extract participant names from the transcript\"\"\"\n",
        "        participants = []\n",
        "        # Look for common name patterns or speaker indicators\n",
        "        name_patterns = re.findall(r'([A-Z][a-z]+)\\s+(?:said|mentioned|stated|asked|replied|suggested|commented)', text)\n",
        "        # Also look for \"I am [Name]\" or \"[Name] here\"\n",
        "        intro_patterns = re.findall(r'(?:I am|This is|My name is)\\s+([A-Z][a-z]+)', text)\n",
        "\n",
        "        # Simple approach: look for capitalized words that might be names\n",
        "        words = text.split()\n",
        "        for word in words:\n",
        "            if (word and word[0].isupper() and len(word) > 2 and word.isalpha() and\n",
        "                word not in ['The', 'This', 'That', 'And', 'But', 'So', 'We', 'They', 'Meeting', 'Today', 'Yesterday', 'Tomorrow']):\n",
        "                participants.append(word)\n",
        "\n",
        "        all_participants = list(set(name_patterns + intro_patterns + participants))\n",
        "        return all_participants[:10]  # Return max 10 participants\n",
        "\n",
        "    def generate_summary(self, text, meeting_title=\"Team Meeting\"):\n",
        "        \"\"\"Generate a summary of the meeting\"\"\"\n",
        "        word_count = len(text.split())\n",
        "        sentence_count = len([s for s in text.split('.') if s.strip()])\n",
        "\n",
        "        # Count action and decision items\n",
        "        action_count = sum(1 for word in self.action_words if word in text.lower())\n",
        "        decision_count = sum(1 for word in self.decision_words if word in text.lower())\n",
        "\n",
        "        summary = f\"Meeting: {meeting_title}\\n\"\n",
        "        summary += f\"Duration: Approximately {word_count // 150} minutes (estimated from {word_count} words)\\n\"\n",
        "        summary += f\"Discussion points: {sentence_count} main statements\\n\"\n",
        "        summary += f\"Action-related mentions: {action_count}\\n\"\n",
        "        summary += f\"Decision-related mentions: {decision_count}\\n\"\n",
        "        summary += \"This meeting covered various topics with actionable outcomes and decisions made by the participants.\"\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def extract_topics(self, text):\n",
        "        \"\"\"Extract key topics using keyword frequency\"\"\"\n",
        "        # Common business/meeting topics\n",
        "        topic_keywords = [\n",
        "            'project', 'budget', 'timeline', 'deadline', 'client', 'customer',\n",
        "            'development', 'marketing', 'sales', 'strategy', 'planning',\n",
        "            'review', 'feedback', 'goals', 'objectives', 'requirements',\n",
        "            'meeting', 'discussion', 'presentation', 'report', 'update'\n",
        "        ]\n",
        "\n",
        "        topics = []\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Check for predefined topics\n",
        "        for keyword in topic_keywords:\n",
        "            if keyword in text_lower:\n",
        "                topics.append(keyword.title())\n",
        "\n",
        "        # Extract frequently mentioned words\n",
        "        words = re.findall(r'\\b\\w+\\b', text_lower)\n",
        "        word_freq = {}\n",
        "        for word in words:\n",
        "            if word not in self.common_words and len(word) > 3:\n",
        "                word_freq[word] = word_freq.get(word, 0) + 1\n",
        "\n",
        "        # Add most frequent words as topics\n",
        "        frequent_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "        for word, count in frequent_words:\n",
        "            if count >= 2:  # Only if mentioned at least 2 times\n",
        "                topics.append(word.title())\n",
        "\n",
        "        return list(set(topics))[:8]  # Return max 8 unique topics"
      ],
      "metadata": {
        "id": "JzCSHLX-6eoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmailGenerator:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def generate_follow_up_email(self, analysis, meeting_title=\"Team Meeting\"):\n",
        "        \"\"\"Generate professional follow-up email\"\"\"\n",
        "        email_template = f\"\"\"\n",
        "Subject: Meeting Summary - {meeting_title}\n",
        "\n",
        "Dear Team,\n",
        "\n",
        "I hope this email finds you well. Below is a summary of our recent meeting:\n",
        "\n",
        "## Meeting Summary\n",
        "{analysis['summary']}\n",
        "\n",
        "## Key Decisions Made\n",
        "\"\"\"\n",
        "\n",
        "        if analysis['decisions']:\n",
        "            for i, decision in enumerate(analysis['decisions'], 1):\n",
        "                email_template += f\"{i}. {decision}\\n\"\n",
        "        else:\n",
        "            email_template += \"No specific decisions were recorded in this meeting.\\n\"\n",
        "\n",
        "        email_template += \"\\n## Action Items\\n\"\n",
        "        if analysis['action_items']:\n",
        "            for i, item in enumerate(analysis['action_items'], 1):\n",
        "                email_template += f\"{i}. {item}\\n\"\n",
        "        else:\n",
        "            email_template += \"No specific action items were identified.\\n\"\n",
        "\n",
        "        if analysis['participants']:\n",
        "            email_template += f\"\\n## Participants\\n\"\n",
        "            email_template += \", \".join(analysis['participants'])\n",
        "\n",
        "        if analysis['key_topics']:\n",
        "            email_template += f\"\\n\\n## Key Topics Discussed\\n\"\n",
        "            email_template += \", \".join(analysis['key_topics'])\n",
        "\n",
        "        email_template += \"\"\"\n",
        "\n",
        "## Next Steps\n",
        "Please review the above items and let me know if I missed anything important.\n",
        "If you have any questions or need clarification on any points, please don't hesitate to reach out.\n",
        "\n",
        "Best Regards,\n",
        "Meeting Assistant\n",
        "\n",
        "---\n",
        "This email was generated automatically by the Meeting Extractor tool.\n",
        "\"\"\"\n",
        "        return email_template"
      ],
      "metadata": {
        "id": "147mouGU6j_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MeetingProcessor:\n",
        "    def __init__(self):\n",
        "        self.audio_processor = AudioProcessor()\n",
        "        self.analyzer = MeetingAnalyzer()\n",
        "        self.email_generator = EmailGenerator()\n",
        "\n",
        "    def process_meeting(self, audio_file_path, meeting_title=\"Team Meeting\"):\n",
        "        \"\"\"Complete Meeting processing pipeline\"\"\"\n",
        "        results = {}\n",
        "        try:\n",
        "            print(\"Step 1: Transcribing Audio....\")\n",
        "            transcription = self.audio_processor.transcribe_audio(audio_file_path)\n",
        "            results['transcription'] = transcription\n",
        "\n",
        "            if not transcription['text']:\n",
        "                raise Exception(\"Transcription Failed or Empty\")\n",
        "\n",
        "            print(\"Step 2: Analyzing meeting content....\")\n",
        "            analysis = self.analyzer.analyze_meeting(transcription, meeting_title)\n",
        "            results['analysis'] = analysis\n",
        "\n",
        "            print(\"Step 3: Generating follow-up email....\")\n",
        "            email = self.email_generator.generate_follow_up_email(analysis, meeting_title)\n",
        "            results['email'] = email\n",
        "\n",
        "            results['status'] = 'success'\n",
        "            print(\"Processing Completed Successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            results['status'] = 'error'\n",
        "            results['error_message'] = str(e)\n",
        "            print(f\"Error During Processing: {str(e)}\")\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "sKVP8X206kjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradio_interface():\n",
        "    \"\"\"Create a User-Friendly Interface with Gradio\"\"\"\n",
        "    processor = MeetingProcessor()\n",
        "\n",
        "    def process_audio_file(audio_file, meeting_title, progress=gr.Progress()):\n",
        "        \"\"\"Process Uploaded audio file with sequential progress tracking\"\"\"\n",
        "        if audio_file is None:\n",
        "            return \"Please upload an Audio File\", \"\", \"\"\n",
        "\n",
        "        start_time = time.time()\n",
        "        try:\n",
        "            # Validate file\n",
        "            if not os.path.exists(audio_file):\n",
        "                return \"Error: Audio file not found\", \"\", \"\"\n",
        "\n",
        "            # STAGE 1: TRANSCRIPTION\n",
        "            progress(0.1, desc=\"🎵 Validating audio file...\")\n",
        "            progress(0.2, desc=\"🎙 Starting transcription...\")\n",
        "            progress(0.3, desc=\"📝 Converting speech to text...\")\n",
        "\n",
        "            # Process the meeting to get results\n",
        "            results = processor.process_meeting(audio_file, meeting_title or \"Team Meeting\")\n",
        "\n",
        "            if results['status'] == 'success':\n",
        "                transcript = results['transcription']['text']\n",
        "                analysis = results['analysis']\n",
        "                email = results['email']\n",
        "\n",
        "                # STAGE 2: ANALYSIS\n",
        "                progress(0.5, desc=\"🧠 Analyzing meeting content...\")\n",
        "                progress(0.6, desc=\"📊 Extracting key insights...\")\n",
        "                progress(0.7, desc=\"✅ Identifying action items...\")\n",
        "\n",
        "                # Format analysis with better structure\n",
        "                analysis_text = f\"\"\"📋 **MEETING SUMMARY**\n",
        "{analysis['summary']}\n",
        "\n",
        "🎯 **KEY DECISIONS**\n",
        "{chr(10).join(f\"• {decision}\" for decision in analysis['decisions']) if analysis['decisions'] else \"• None identified\"}\n",
        "\n",
        "✅ **ACTION ITEMS**\n",
        "{chr(10).join(f\"• {item}\" for item in analysis['action_items']) if analysis['action_items'] else \"• None identified\"}\n",
        "\n",
        "👥 **PARTICIPANTS**\n",
        "{', '.join(analysis['participants']) if analysis['participants'] else \"None identified\"}\n",
        "\n",
        "💡 **KEY TOPICS DISCUSSED**\n",
        "{', '.join(analysis['key_topics']) if analysis['key_topics'] else \"None identified\"}\n",
        "\"\"\"\n",
        "\n",
        "                # STAGE 3: EMAIL GENERATION\n",
        "                progress(0.8, desc=\"📧 Generating follow-up email...\")\n",
        "                progress(0.9, desc=\"✉ Formatting email content...\")\n",
        "                progress(0.95, desc=\"🎯 Finalizing email...\")\n",
        "\n",
        "                # Complete processing\n",
        "                elapsed_time = time.time() - start_time\n",
        "                progress(1.0, desc=f\"✅ All tasks completed! ({elapsed_time:.1f}s)\")\n",
        "\n",
        "                return transcript, analysis_text, email\n",
        "            else:\n",
        "                return f\"❌ Error: {results['error_message']}\", \"\", \"\"\n",
        "\n",
        "        except Exception as e:\n",
        "            elapsed_time = time.time() - start_time\n",
        "            return f\"❌ Error Processing File ({elapsed_time:.1f}s): {str(e)}\", \"\", \"\"\n",
        "\n",
        "    # Create interface\n",
        "    with gr.Blocks(\n",
        "        title=\"🎯 AI-Powered Meeting Extractor\",\n",
        "        theme=gr.themes.Soft(),\n",
        "        css=\"\"\"\n",
        "        .gradio-container {\n",
        "            max-width: 1200px !important;\n",
        "        }\n",
        "        .progress-bar {\n",
        "            background: linear-gradient(90deg, #ff6b35, #f7931e) !important;\n",
        "        }\n",
        "        .header-section {\n",
        "            text-align: center;\n",
        "            padding: 20px;\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            color: white;\n",
        "            border-radius: 10px;\n",
        "            margin-bottom: 20px;\n",
        "        }\n",
        "        \"\"\"\n",
        "    ) as interface:\n",
        "        # Header Section\n",
        "        with gr.Row():\n",
        "            gr.HTML(\"\"\"\n",
        "            <div class=\"header-section\">\n",
        "                <h1>🎯 AI-Powered Meeting Extractor</h1>\n",
        "                <p>Transform your meeting recordings into actionable insights, transcripts, and follow-up emails</p>\n",
        "            </div>\n",
        "            \"\"\")\n",
        "\n",
        "        # Input Section\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=2):\n",
        "                gr.Markdown(\"### 📁 Upload Meeting Audio\")\n",
        "                gr.Markdown(\"*Supported formats: MP3, WAV, M4A, FLAC*\")\n",
        "                audio_input = gr.Audio(\n",
        "                    type=\"filepath\",\n",
        "                    label=\"Choose Audio File\"\n",
        "                )\n",
        "\n",
        "                gr.Markdown(\"*Help us generate a more relevant analysis*\")\n",
        "                title_input = gr.Textbox(\n",
        "                    label=\"📝 Meeting Title (Optional)\",\n",
        "                    placeholder=\"e.g., Weekly Team Standup, Project Planning Meeting\"\n",
        "                )\n",
        "\n",
        "                with gr.Row():\n",
        "                    process_btn = gr.Button(\n",
        "                        \"🚀 Process Meeting\",\n",
        "                        variant=\"primary\",\n",
        "                        size=\"lg\"\n",
        "                    )\n",
        "                    clear_btn = gr.Button(\n",
        "                        \"🗑 Clear All\",\n",
        "                        variant=\"secondary\"\n",
        "                    )\n",
        "\n",
        "        # Status Section\n",
        "        with gr.Row():\n",
        "            status_display = gr.Markdown(\"📊 Ready to process your meeting audio\")\n",
        "\n",
        "        # Output Section\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### 📝 Meeting Transcript\")\n",
        "                transcript_output = gr.Textbox(\n",
        "                    label=\"Full Transcript\",\n",
        "                    lines=20,\n",
        "                    max_lines=25,\n",
        "                    show_copy_button=True,\n",
        "                    container=True\n",
        "                )\n",
        "\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### 📊 Meeting Analysis\")\n",
        "                analysis_output = gr.Textbox(\n",
        "                    label=\"Key Insights & Analysis\",\n",
        "                    lines=15,\n",
        "                    max_lines=20,\n",
        "                    show_copy_button=True,\n",
        "                    container=True\n",
        "                )\n",
        "\n",
        "        gr.Markdown(\"### 📧 Follow-up Email\")\n",
        "        email_output = gr.Textbox(\n",
        "            label=\"Generated Email\",\n",
        "            lines=12,\n",
        "            max_lines=15,\n",
        "            show_copy_button=True,\n",
        "            container=True\n",
        "        )\n",
        "\n",
        "        # Event Handlers\n",
        "        def update_status(message):\n",
        "            return f\"📊 {message}\"\n",
        "\n",
        "        def clear_all():\n",
        "            return None, \"\", \"\", \"\", \"\", update_status(\"Ready to process your meeting audio\")\n",
        "\n",
        "        # Process button click\n",
        "        process_btn.click(\n",
        "            fn=process_audio_file,\n",
        "            inputs=[audio_input, title_input],\n",
        "            outputs=[transcript_output, analysis_output, email_output],\n",
        "            show_progress=True\n",
        "        )\n",
        "\n",
        "        # Clear button click\n",
        "        clear_btn.click(\n",
        "            fn=clear_all,\n",
        "            outputs=[\n",
        "                audio_input,\n",
        "                title_input,\n",
        "                transcript_output,\n",
        "                analysis_output,\n",
        "                email_output,\n",
        "                status_display\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # File upload status\n",
        "        audio_input.change(\n",
        "            fn=lambda x: update_status(f\"Audio file uploaded: {os.path.basename(x) if x else 'No file selected'}\"),\n",
        "            inputs=[audio_input],\n",
        "            outputs=[status_display]\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    return interface\n",
        "\n",
        "# Initialize the interface\n",
        "interface = gradio_interface()"
      ],
      "metadata": {
        "id": "sZlvI3Ay6kf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27759294-80f5-49aa-9450-0ff2ba3a0997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Whisper Model: base\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 58.2MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisper Model Loaded Successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Meeting Extractor - Google Colab Version\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Setup complete!\")\n",
        "print(\"Upload an audio file to start processing\")\n",
        "print(\"The interface will appear below\")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch(\n",
        "    share=True,  # Creates a public link\n",
        "    debug=True,\n",
        "    height=800,\n",
        "    show_error=True\n",
        ")"
      ],
      "metadata": {
        "id": "nyWy-5z06kck",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "149c45b2-532c-441a-df5a-dbe762ec86b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meeting Extractor - Google Colab Version\n",
            "==================================================\n",
            "Setup complete!\n",
            "Upload an audio file to start processing\n",
            "The interface will appear below\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://ad73b3053b8c075475.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ad73b3053b8c075475.gradio.live\" width=\"100%\" height=\"800\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Transcribing Audio....\n",
            "Starting transcription.....\n",
            "Transcription Completed\n",
            "Step 2: Analyzing meeting content....\n",
            "Step 3: Generating follow-up email....\n",
            "Processing Completed Successfully!\n"
          ]
        }
      ]
    }
  ]
}